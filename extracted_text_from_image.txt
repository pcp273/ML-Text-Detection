If scale up this architecture and train it on a large dataset of faces, you can get
fairly realistic images. In fact, DCGANs can learn quite meaningful latent representa_
tions, as you can see in Figure 17-18: many images were generated, and nine of them
were picked manually (top left), including three representing men with glasses, three
men without glasses, and three women without glasses. For each of these categories
the codings that were used to generate the images were averaged, and an image was
generated based on the resulting mean codings (lower left). In short, each of the three
lower-left images represents the mean of the three images located above it. But this is
not a simple mean computed at the pixel level (this would result in three overlapping
faces), it is a mean computed in the latent space, so the images still look like normal
faces. Amazingly, if you compute men with glasses, minus men without glasses, plus
women without glasses—where each term corresponds to one of the mean codings—
and you generate the image that corresponds to this coding, you get the image at the
center of the 3 x 3 grid of faces on the right: a woman with glasses! The eight other
images around it were generated based on the same vector plus a bit of noise, to illus-
trate the semantic interpolation capabilities of DCGANs. Being able to do arithmetic
on faces feels like science fiction!
